{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-prior",
   "metadata": {},
   "source": [
    "# Unconventional Data Sources\n",
    "###### Cole Plum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-exchange",
   "metadata": {},
   "source": [
    "### PDF Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spread-fisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         2640\n",
       ".           2323\n",
       "of          1580\n",
       "to          1384\n",
       "and         1174\n",
       "a            977\n",
       "in           694\n",
       "is           612\n",
       "for          524\n",
       "that         507\n",
       "be           431\n",
       "data         407\n",
       "The          361\n",
       "are          349\n",
       "with         337\n",
       "as           307\n",
       "students     259\n",
       "can          257\n",
       "this         247\n",
       "course       233\n",
       "it           222\n",
       "or           221\n",
       "on           210\n",
       "an           190\n",
       "their        182\n",
       "was          176\n",
       "Data         171\n",
       "by           171\n",
       "not          168\n",
       "I            155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "doc = fitz.open('dissertation.pdf')\n",
    "text = \"\".join(page.get_text(\"text\") for page in doc)\n",
    "words = pd.Series(text.split())\n",
    "words.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intimate-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>2020 Fall Term</td>\n",
       "      <td></td>\n",
       "      <td>2021 Fall Term</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First Day of Classes</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labor Day - Classes Will Meet</td>\n",
       "      <td>Mon</td>\n",
       "      <td>September 7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labor Day - Classes Suspended</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Mon</td>\n",
       "      <td>September 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last day to add or drop courses</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 15</td>\n",
       "      <td>Tue</td>\n",
       "      <td>September 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Summer Session - 10 week - classes begin</td>\n",
       "      <td>Mon</td>\n",
       "      <td>June 7</td>\n",
       "      <td>Mon</td>\n",
       "      <td>June 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Last day to add or drop courses</td>\n",
       "      <td>Wed</td>\n",
       "      <td>June 16</td>\n",
       "      <td>Wed</td>\n",
       "      <td>June 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Last day to change registration or withdraw fr...</td>\n",
       "      <td>Thur</td>\n",
       "      <td>July 15</td>\n",
       "      <td>Thur</td>\n",
       "      <td>July 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Final Exams</td>\n",
       "      <td>Fri</td>\n",
       "      <td>August 13</td>\n",
       "      <td>Fri</td>\n",
       "      <td>August 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Deadline for 10-week grades to be posted to UDSIS</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 17</td>\n",
       "      <td>Tue</td>\n",
       "      <td>August 16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0               1  \\\n",
       "0                                                Fall  2020 Fall Term   \n",
       "1                                First Day of Classes             Tue   \n",
       "2                       Labor Day - Classes Will Meet             Mon   \n",
       "3                       Labor Day - Classes Suspended                   \n",
       "4                     Last day to add or drop courses             Tue   \n",
       "..                                                ...             ...   \n",
       "70           Summer Session - 10 week - classes begin             Mon   \n",
       "71                    Last day to add or drop courses             Wed   \n",
       "72  Last day to change registration or withdraw fr...            Thur   \n",
       "73                                        Final Exams             Fri   \n",
       "74  Deadline for 10-week grades to be posted to UDSIS             Tue   \n",
       "\n",
       "               2               3             4  \n",
       "0                 2021 Fall Term                \n",
       "1    September 1             Tue     August 31  \n",
       "2    September 7                                \n",
       "3                            Mon   September 6  \n",
       "4   September 15             Tue  September 14  \n",
       "..           ...             ...           ...  \n",
       "70        June 7             Mon        June 6  \n",
       "71       June 16             Wed       June 15  \n",
       "72       July 15            Thur       July 14  \n",
       "73     August 13             Fri     August 12  \n",
       "74     August 17             Tue     August 16  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import camelot\n",
    "tables = camelot.read_pdf('calendar.pdf')\n",
    "df = tables[0].df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suffering-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the           18\n",
       "a             10\n",
       "Yes           10\n",
       "No            10\n",
       "of             9\n",
       "              ..\n",
       "enough?        1\n",
       "much           1\n",
       "does           1\n",
       "part           1\n",
       "algorithm!     1\n",
       "Length: 229, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open('Final Algorithm Flowchart.pdf')\n",
    "text = \"\".join(page.get_text(\"text\") for page in doc)\n",
    "words = pd.Series(text.split())\n",
    "words.value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-grain",
   "metadata": {},
   "source": [
    "### Reddit Image Transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fundamental-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98828125\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "-0.4\n",
      "0.2725\n",
      "-0.7\n",
      "0.0\n",
      "0.0\n",
      "0.390625\n",
      "0.22421875\n",
      "0.35\n",
      "0.25\n",
      "0.05\n",
      "-0.5\n",
      "0.0\n",
      "0.03285714285714285\n",
      "0.51\n",
      "0.5\n",
      "0.0\n",
      "0.41818181818181815\n",
      "0.5\n",
      "0.0\n",
      "\n",
      " |           18\n",
      "THE          8\n",
      "TO           7\n",
      "A            7\n",
      "to           7\n",
      "            ..\n",
      "19!          1\n",
      "practice     1\n",
      "Time’s       1\n",
      ">            1\n",
      "girls.       1\n",
      "Length: 415, dtype: int64 \n",
      "\n",
      "['dude', 'love rock', 'hell yeah', 'like rock', 'rock', 'the best', 'mrlovenstein.com', \"\\\\ 'm\", 'dying', 'call', 'you have to call', 'it', '’ s', 'okay', 'understand', 'remi_lascault', '[ ngewe', 'cc', 'drowning in the burdens of my lifes man', \"you're\", 'fish', 'vve got fish burdens', 'poorly drawn lines', 'the', 'slime', 'beginners blade', 'welcome to your first dungeon', 'don t think were ready for that just yet', \"let's come back later with some ice magi— h—-hey\", 'don t just leave', 't feel ugly', '“ m', 'going to dress vp', 'felissabumblehead', '@ © ersychosuzanne', 'pet-proof', 'wow to eat swake comics thanks', 'meatball sub', 'sure', \"'s ... um\", 'may', 'pretty neat', 'instagram.com/sewergrandpascomics twitter.com/sewergrandpa', 'getting angry because ano', \"ca n't fall asleep\", \"ca n't fall asleep\", 'because', 'getting angry', 'neevtewic oh my gop t off ladder and my chainsaw lie still', 't know', 'jimbenton.com', '+ instagram.com/jimbentonshots', 'oh', 'cole', 'carly', 'wait', 'earth', '{ __—_ ] }', 'smart', 'dumb girls', 'fea', 'dude', 'mm', 'hey', 'cole', 'algebra', 'wana ttt wk', 'gi', 'rn — | | = | = | om', 'l oa', 'cte lu', 'yl | |', 'er x', 'hlt an', 's = — sitll x', 'oe ae', 'brian ls', 'picture it', 'fruit fly', 'but with the mind of albert einstein', 'it', '’ s', 'and he has', 'hours to discover the general theory of relativity before the real einstein beats him to it', 'will he succeed', 'fistful of zebras no', 'instead', 'he fucks', 'good lord he fucks', 'its', 'genius fruit fly fuckfest without', 'care in the world for science', 'then he dies and it doesn', 't matter anyway because he never would have had the balls to publish', '“ lie-brary ” haho amirite bruv', 'step', 'train', 'obviousty', \"| wouldn'+\", 'friends +o practice', 'ripote } @ sheepish games time ’ s', 'ahahahahahahahahaha', 'hahahahahahahahahah hahahahahahahahahah', 'rat da', 'well', 'life ...', 'mot', 'mi <', 't @ mildnihilist |', 'well', 'good start ... land boyfriend', '®danbydraws danby draws.com', 'ics _', 'can', 'have', 'bite', 'sure', 'fi #', 'instagram.com/kubbs_hd', 'hope', 'grimace looks like tommy si€ger'] \n",
      "\n",
      "©           3\n",
      "1           3\n",
      "friends     3\n",
      "because     3\n",
      "just        3\n",
      "this        3\n",
      "hey         3\n",
      "rock        3\n",
      "make        3\n",
      "n't         3\n",
      "in          3\n",
      "like        4\n",
      "for         4\n",
      "’           4\n",
      "with        4\n",
      "have        4\n",
      "of          5\n",
      "my          5\n",
      "and         5\n",
      "is          5\n",
      "t           7\n",
      "he          7\n",
      "m           8\n",
      "it          9\n",
      "s           9\n",
      "you         9\n",
      "the        10\n",
      "i          11\n",
      "a          13\n",
      "to         14\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pprint\n",
    "from PIL import Image\n",
    "import io\n",
    "import pytesseract\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Set a User Agent to avoid being blocked\n",
    "data = requests.get(\"https://www.reddit.com/r/comics/.json\", headers = {'User-agent': 'your bot 0.1'}).json()\n",
    "#pprint.pprint(data)\n",
    "map = {}\n",
    "for child in data['data']['children']:\n",
    "    if(child['data']['url'].endswith(\".png\") or child['data']['url'].endswith(\".jpg\") or \n",
    "       child['data']['url'].endswith(\".jpeg\") or child['data']['url'].endswith(\".jfif\")):\n",
    "        map[child['data']['title']] =  child['data']['url']\n",
    "\n",
    "all_text = \"\"\n",
    "for url in list(map.values()):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    all_text += text\n",
    "    \n",
    "    blob = TextBlob(text)\n",
    "    print(blob.sentiment.polarity)\n",
    "    # Value from -1 to 1 about how positive/negative the post's words are\n",
    "\n",
    "words = pd.Series(all_text.split())\n",
    "print('\\n', words.value_counts(), '\\n')\n",
    "\n",
    "blob = TextBlob(all_text)\n",
    "print(blob.noun_phrases, '\\n')\n",
    "\n",
    "# Sorted with pandas\n",
    "print(pd.Series(blob.word_counts).sort_values().tail(30), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-traffic",
   "metadata": {},
   "source": [
    "##### Dogecoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "improved-extreme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reddit', 'reddit premium = > oo', 'ba', 'c ew', '—| ry-|', 'oo [ -t', '— ] ‘', 'a. “', 'hole el', 'ba se ss g54', 'dooloe—', 'gg-t-', 'son non', 'veare', 'scoccccoce ccea be der', 'li lrn', 'ees cs re ny', 'sy o', 'paakareaaiiidgisi ddd did dos', 'tesla', 'doge', 'millionaires', 'billionaires', '= |', 'reddit', '—— pay', 'reddit', 'elon musk', '@ ky @ elonmusk', 'dyomv', '{ ol6', 'mm', '\\\\\\\\c- ] alam', 'l=ss', 'mcok- [ erer-', 'dlole', 'wa', 'xe', 'may', 'twitter', 'search', 'lte', '% 0_', 'rq xora', 'ce', 'gc s6.26m', 'balance', 't e', 'bybit', 'bonus bash', 'win', 'bonus', '@ plete } = $ 6.25m $', '% ——_ cane oo', '— | \\\\ id', 'nal aici', 'win', 'bonus', 'bybit', 'bonus bash vo mire', 'portfolio elon musk', 'tony stark', 'game', 'level sacrifice', 'entire stock', 'tesla', 'support dogecoin', 'absolute legend', 'elon', 'november', 'een hits', 'blunt .. ‘', 'people ”', 'new wealth |', 'travel space .. ’', 'elon musk', '@ @ elonmusk', 'tesla', 'doge', 'twitter', 'iphone 15k', 'retweets', 'quote tweets', 'likes', 'tt y', 'tim culpan', '@ @ tculpan', '5h ore', 'dogecoin', 'dogecoin may be', 'hustle', 'mom', 'luesv', 'bloomberg.com ©', 'qo', '{ f', 'elon musk', '@ @ elonmusk', '‘ _', 'exactly', 'doge', 'harvey', 'tittabawassee saginaw', 'mi', '989-401-4424 qo', 'approyv myut', 'ap', '.96 bay', 'jorky ype _/', 'era be cli', 'stp totay', 'sh', 'agrgemeny ”', 'x uy', 'pi', 'dont forget your loyalty points today', 'bcx', 'sport streetwear vinyl comicbook skate rental all brands', 'home /', 'secure', 'secure', 'payment ©', 'online', '/ credit', 'debit card /', 'blik', 'fast', 'online payments', 'dotpay', 'safe polish oparators', '= > © ren ¥ ipko', 'gree', 'bins mee', 'pivsc bank re', 'oo', '== @ c', 'b=', 'see', 'eens i=', 'visa id8e goss', 'ing ss', 'ose esd', 'u pani kopin ae sepa tustpay', 'sonysote @', 'dogecoin', 'dogecoin', 'coinpayments', 'wow', 'daigbgs5ru7i3skdvnkpnev4c8nj44a5iwm', '= |', 'connect', 'weed-doge', '@ e', 'apr', '% = < ]', 'deposit fee', 'weed earned weed-doge staked', 'py =\\\\ ¢=', 'don ’ t', 'short doge'] \n",
      "\n",
      "23           3\n",
      "am           3\n",
      "you          3\n",
      "0            3\n",
      "be           3\n",
      "elonmusk     3\n",
      "accept       3\n",
      "via          3\n",
      "should       3\n",
      "tesla        3\n",
      "e            3\n",
      "oo           4\n",
      "s            4\n",
      "doge         4\n",
      "—            4\n",
      "of           4\n",
      "4            4\n",
      "musk         4\n",
      "for          4\n",
      "bonus        4\n",
      "reddit       4\n",
      "t            5\n",
      "elon         5\n",
      "and          5\n",
      "to           7\n",
      "dogecoin     7\n",
      "i            7\n",
      "the          7\n",
      "©            9\n",
      "a           12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set a User Agent to avoid being blocked\n",
    "data = requests.get(\"https://www.reddit.com/r/dogecoin/.json\", headers = {'User-agent': 'your bot 0.1'}).json()\n",
    "#pprint.pprint(data)\n",
    "map = {}\n",
    "for child in data['data']['children']:\n",
    "    if(child['data']['url'].endswith(\".png\") or child['data']['url'].endswith(\".jpg\") or \n",
    "       child['data']['url'].endswith(\".jpeg\") or child['data']['url'].endswith(\".jfif\")):\n",
    "        map[child['data']['title']] =  child['data']['url']\n",
    "\n",
    "\n",
    "all_text = \"\"\n",
    "for url in list(map.values()):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    all_text += text\n",
    "\n",
    "blob = TextBlob(all_text)\n",
    "print(blob.noun_phrases, '\\n')\n",
    "\n",
    "# Sorted with pandas\n",
    "print(pd.Series(blob.word_counts).sort_values().tail(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-fight",
   "metadata": {},
   "source": [
    "### OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprising-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "images = ['cakeboss', 'gordon', 'simon']\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "for image in images:\n",
    "    img = cv2.imread(\"images/\" + image + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "    cv2.imwrite(\"images/\" + image + \"_detected.jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-contamination",
   "metadata": {},
   "source": [
    "##### w/ Smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constant-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "for num in range(1,4):\n",
    "    img = cv2.imread(\"images/smile\" + str(num) + '.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in smiles:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "    cv2.imwrite(\"images/smile\" + str(num) + \"_detected.jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-singles",
   "metadata": {},
   "source": [
    "The smile cla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
